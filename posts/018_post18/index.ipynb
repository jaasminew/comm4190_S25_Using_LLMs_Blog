{
 "cells": [
  {
   "cell_type": "raw",
   "id": "740c25c4-668a-4c53-8efe-0008ef6c42e6",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Prompt Engineering 2.0: Refining prompting templates for AIdeator\"\n",
    "description: \"After wrapping up the backend development of AIdeator, I still found the quality of product ideas in test runs unsatisfying. In this post, I took a second deep dive into the prompt engineering of this ideation tool.\"\n",
    "author: \"Jasmine Wang\"\n",
    "date: \"4/11/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - product development\n",
    "  - creativity\n",
    "  - ideation\n",
    "  - prompt engineering\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a35af-eda5-43b6-8e4b-aadc67027459",
   "metadata": {},
   "source": [
    "## Refining the prompting templates\n",
    "\n",
    "With a functioning “UI” running in my terminal, I conducted a few test runs using the ideation tool. However, I wasn’t fully satisfied with the quality of the output. It turns out that generating a standardized template for a creative workflow is inherently challenging and requires a significant amount of refinement. As a result, I decided to rework my prompting templates before connecting the backend to the frontend to ensure a more polished and reliable experience.\n",
    "\n",
    "![](hero-img.jpg)\n",
    "\n",
    "Instead of completely rewriting the prompts, I focused on making more nuanced tweaks to the wording. In many cases, I found my original prompts to be **too vague or underspecified**, which led to ambiguities in the generated output. Put simply, the instructions were often too abstract and difficult for the model to interpret or measure effectively.\n",
    "\n",
    "Below, I’ve summarized some of the key insights I gained from this second round of prompt engineering.\n",
    "\n",
    "### 1. Be specific in requirements.\n",
    "LLMs are particularly effective at **interpreting specific, well-defined language**. Much like when using GPT-4o’s image generation feature, the quality of the output significantly improves when the prompt includes quantifiable or concrete criteria. Without clear instructions, it’s easy to unintentionally introduce ambiguities or double standards, resulting in output that may drift far from the original intent or user expectations.\n",
    "\n",
    "This highlights the importance of treating prompts not as casual instructions, but as precise design specifications. Just as a designer wouldn’t submit a vague wireframe to a developer, prompt engineers should avoid overly abstract language when working with LLMs. Adding examples, defining edge cases, or even specifying the format of the response can dramatically improve consistency and relevance—especially in workflows where creativity needs to be balanced with clarity and structure.\n",
    "\n",
    "Here’s a quick example. In one prompt template, I asked the LLM to generate five different imaginary customer profiles, with the vague instruction to ensure they were “differentiated enough.” However, I wasn’t satisfied with the results. The issue was that the LLM didn’t actually understand what “differentiated” meant in this context, nor how to evaluate whether two profiles were distinct enough from one another.\n",
    "\n",
    "To solve this, I revised the prompt to be more explicit:\n",
    "\n",
    "> Come up with 5 diverse, highly specific user profiles, each having a short description (e.g., name, age, occupation). Each persona must differ significantly in either background, industry, occupation, age, or daily habits.\n",
    "\n",
    "In this way, I provided the model with clear and measurable criteria for what constitutes meaningful differentiation. Instead of relying on vague language, the updated prompt gives the LLM a defined set of dimensions to vary across, leading to much more diverse and realistic user personas. This small change significantly improved the quality of the output and reinforced the value of precise, constraint-driven prompting—especially in tasks that require structured creativity.\n",
    "\n",
    "### 2. Be specific in methodology.\n",
    "The same rule applies to methodology. When aiming for a specific outcome, it’s often more effective to guide the LLM through a step-by-step process, rather than simply stating the desired result. By dictating the method—the logic or structure the model should follow—you gain more control over the output, making it more consistent, manageable, and aligned with your intent.\n",
    "\n",
    "This approach also helps reduce ambiguity and model drift, especially in creative or open-ended tasks. Breaking down the problem into smaller, more interpretable steps allows the LLM to build upon each response more thoughtfully, resulting in higher-quality, more purposeful output that better mirrors human reasoning.\n",
    "\n",
    "For example, when I was prompting the LLM to combine two distant concepts in creative ways, instead of vaguely saying “ensure the final product is not just a jumble of features—explain how they coalesce into a cohesive whole,” I opted for more directive, structured instructions:\n",
    "\n",
    "> Choose the approach (or approaches) you find most relevant from the following concise options:\n",
    ">\t•\tAnalogy Swapping: Borrow one concept’s structure or approach and apply it to the other’s domain.\n",
    ">\t•\tInversion/Role Reversal: Flip the assumptions of one concept to serve the opposite goal within the other.\n",
    ">\t•\tContextual Transplant: Transfer a principle from one field and use it in a radically different context.\n",
    ">   ....\n",
    "\n",
    "In this way, I shifted the focus from a broad, interpretive task to a method-driven exploration, giving the model a framework for creativity. This not only improved the quality and cohesion of the generated ideas but also made the process more predictable and easier to evaluate.\n",
    "\n",
    "### 3. Pay extreme attention to output formatting\n",
    "When building an LLM application, one critical aspect that demands close attention is the standardization of the output format. This becomes especially important when connecting backend-generated data to a frontend UI, where even slight inconsistencies can lead to rendering issues or broken interactions. For my project, this meant ensuring that every output adhered strictly to a predefined JSON format, down to the structure, key names, and data types.\n",
    "\n",
    "Initially, I gave the LLM a vague instruction to “produce a JSON file” as the output. However, I soon realized that the JSON structures it generated varied significantly—not only across different prompts but even within multiple runs of the same prompt. These inconsistencies made it difficult to process and display the data reliably on the frontend.\n",
    "\n",
    "To solve this, I revised my prompt to be much more explicit:\n",
    "\n",
    "> Please structure this user idea into a JSON format with the following fields:\n",
    "> 1. \"heading\": A concise and faithful description of user input (5-7 words)\n",
    "> 2. \"explanation\": A brief explanation of this concept (1-2 sentences)\n",
    "> 3. \"productDirection\": A practical product direction for solving or leveraging this concept (1-2 sentences)\n",
    "\n",
    "I also included an example output at the end of the prompt to give the LLM a clear reference point. This drastically improved the consistency and reliability of the generated JSON, making it much easier to integrate with the frontend UI.\n",
    "\n",
    "### 4. Simplify the prompt to reduce tokens (cost)\n",
    "Finally, prompt length is another crucial factor to consider—especially if the LLM application has commercial potential. A longer prompt not only increases the API usage cost, but can also lead to longer processing times. While this may not be a major concern for a class project, I’m currently using my personal OpenAI account for API calls, so I have a very real sense of how quickly the costs can add up—even during simple test runs. If the tool were to scale, keeping costs low would be a necessary and strategic priority.\n",
    "\n",
    "To address this, I carefully reviewed each prompt before finalizing it, ensuring that it contained only the essential information. I ran multiple tests in my desktop ChatGPT to confirm that the streamlined prompts still produced output of the same quality and clarity as the original, more verbose versions. This optimization step was key to balancing performance, cost-efficiency, and usability.\n",
    "\n",
    "## Summary\n",
    "At the end of the day, I realized that prompt engineering is all about **trade-offs**. The more specific and structured your instructions are, the more standardized and controllable the output becomes. But at the same time, the more you constrain the model, the less creative and surprising its responses tend to be.\n",
    "\n",
    "There’s a certain irony in using such a rigid, directive approach to guide a process as inherently open-ended as brainstorming. Yet, this has proven to be the most effective way to inject human ingenuity into machine-generated ideas. When creativity emerges from patterns in massive datasets, it’s already an artificial construction—-so shaping it with intentional prompts is not just necessary, but perhaps the only way to make it feel truly meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796b429a-267b-4d62-8a4c-a71e8eaa0f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
