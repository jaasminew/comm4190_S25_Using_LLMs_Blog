{
 "cells": [
  {
   "cell_type": "raw",
   "id": "417d4ff3-e8ab-445a-9b62-4f33a4ef8902",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Prompt engineering for LLM ideation Part 2\"\n",
    "description: \"Inspired by my experiments with LLMs, I set out to build an ideation partner using Open AI API, that helps humans yield better ideation results than a basic idea generator.\"\n",
    "author: \"Jasmine Wang\"\n",
    "date: \"3/22/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - product development\n",
    "  - creativity\n",
    "  - ideation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c497292-885e-4bd2-afa6-549197c54fd4",
   "metadata": {},
   "source": [
    "# Construct the ideation prompting\n",
    "\n",
    "Continuing from the last post, I'm going to complete and polish the prompt for the co-brainstorming session. In the previous post, I outlined the overall workflow of the ideation process and constructed a LangChain workflow diagram listing all the steps and different types of chain that are used. In this post, I'll be working on refining the prompt.\n",
    "\n",
    "![](hero-img.jpg)\n",
    "\n",
    "## Workflow (Part 2)\n",
    "The main goal here is to instruct the LLM to co-create product ideas by helping complete a mind map. As I explained earlier, a mind map is built around a network of interrelated concepts that connect and branch out from one another. After analyzing several innovation templates, I distilled the process into three key methods: 1. Identifying emotional root causes 2. Discovering deeper, non-obvious connections 3. Generating imaginary customer feedback.\n",
    "\n",
    "Completing the mind map requires input from both the LLM and the human user. This challenge breaks down into two main tasks: One, instructing the LLM to generate concepts and keywords; two, enabling the LLM to respond to human input and expand on those branches. The first task is more complex but can be handled effectively with well-crafted instructions. The second task might seem simple—essentially just continuing a conversation—but it raises important considerations like how the LLM interprets user input and how to generate thoughtful, contextually relevant responses. These subtle challenges require more attention than they appear at first glance.\n",
    "\n",
    "For now, I’ve decided to focus on the first task—-building a solid foundation by guiding the LLM to generate meaningful concepts and keywords.\n",
    "\n",
    "Building on my findings from previous posts—where I refined the prompt to help LLMs form more nuanced connections, think emotionally, and generate imaginary user personas—I’ve summarized each method into a clear set of steps.\n",
    "\n",
    "There’s no way to know which prompt works best without testing it in a simulated ideation environment. So, I used the prompt: “Design a tool to help college students and young professionals with short attention spans focus more easily” as the base challenge. I worked with the LLM through the entire process—from problem statement generation to mind map creation.\n",
    "\n",
    "For each trial, I tweaked the wording in the prompt to fine-tune the model’s responses and improve the output.\n",
    "\n",
    "After several runs, I was satisfied with the refined prompt. A fraction of the final prompt looks like this:\n",
    "\n",
    "> There are many different ways to structure the branches, we can use the following ones:\n",
    ">\n",
    "> 1. Emotional Root Causes\n",
    ">\n",
    "> Follow these steps when doing this:\n",
    ">\n",
    "> a. Emotional Seeds\n",
    ">\n",
    "> “Identify 5 core emotional root causes that lead to the problem. What feelings (e.g., anxiety, longing, excitement) do people experience? Why do these emotions arise? Present them as bullet points with brief explanations (e.g., ‘fear of letting others down,’ ‘need for recognition’). Under each root cause, suggest a corresponding suggested direction the product may take.”\n",
    ">\n",
    "> b. Habit & Heuristic Alignment\n",
    ">\n",
    ">....\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Give it a try\n",
    "\n",
    "Using the same design challenge I mentioned above (“Design a tool to help college students and young professionals with short attention spans focus more easily”), I tested the prompt. Since the full response would be too long, GPT executed each step separately.\n",
    "\n",
    "Here’s a glimpse of the output. \n",
    "\n",
    "![](step-1-1.png)\n",
    "\n",
    "![](step-1-2.png)\n",
    "\n",
    "![](step-2-1.png)\n",
    "\n",
    "Overall, I was very satisfied with the results. The process provided me with a range of fresh perspectives and potential directions for my new product. However, a few weaknesses still need to be addressed moving forward:\n",
    "\n",
    "1.\t**Standardized Output Format:**\n",
    "Since this tool is intended to be developed as a web app, the output needs to follow a consistent format for easier integration and presentation. Currently, the outputs from different steps vary significantly in structure, creating unnecessary challenges when it comes to cleaning and organizing the content.\n",
    "\n",
    "2.\t**Fragmented Ideas and Lack of Cohesion:**\n",
    "While the suggested directions and concepts are interesting and creative, they often feel fragmented. As a product designer, I found the tool most helpful when I already had a base idea and was looking for add-ons or enhancements. However, because these ideas are generated using different methodologies with little connection between them, it’s difficult to establish a common thread or cohesive foundation that sets the tone for the entire product. \n",
    "\n",
    "Based on these insights, I came up with a few changes to improve the process:\n",
    "\n",
    "1.\tUnder each step, I plan to add a small section called **“sample format”** to keep the output consistent. However, which format works best for users is still unclear. Since this ties closely to UX/UI design, I’ve decided to run a few user tests before finalizing it.\n",
    "  \n",
    "2.\tThere are a couple of ways to address the fragmentation issue. One option is to use **AI summarization** to distill all potential directions into a few common threads, providing a quick reference for users to decide which path to explore. Another, less intrusive approach is to **color-code** similar product ideas or concepts, making it easier for users to spot patterns. Ultimately, this comes down to understanding how a product idea is formed and what kind of information the ideator needs during the process.\n",
    "\n",
    "  \n",
    "3.\tOne final consideration is the **length of the instructions**. Although I don’t have a clear solution yet, I worry that overly long instructions might reduce the LLM’s efficiency and effectiveness. I still need to figure out whether it’s better to input everything at once or break the instructions into smaller chunks and feed them step by step. This will require further testing.\n",
    "\n",
    "I’m holding off on finalizing the Reminder section for now, as there are still some ambiguities around user needs. In the next post, I’ll share insights from conversations with students and creative professionals about their experiences with ideation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb9bea-458b-4c86-b0ee-6dae0fbd401a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
