<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.43">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jasmine Wang">
<meta name="dcterms.date" content="2025-03-26">
<meta name="description" content="Leanring how Google approaches AI tools that facilitate human-AI collaboration.">

<title>A deep look into Google’s AI tools – Jasmine's explorations of LLMs</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-d4d76bf8491c20bad77d141916dc28e1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-8647a4a42273f773479d27c00df3f9ed.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Jasmine’s explorations of LLMs</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/jaasminew"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">A deep look into Google’s AI tools</h1>
                  <div>
        <div class="description">
          Leanring how Google approaches AI tools that facilitate human-AI collaboration.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">LLMs</div>
                <div class="quarto-category">product review</div>
                <div class="quarto-category">NotebookLM</div>
                <div class="quarto-category">Learn About</div>
                <div class="quarto-category">AI productivity</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Jasmine Wang </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 26, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>In this post, I took a deep dive into three of Google’s AI products: NotebookLM, TextFX and Learn About. My goal was to understand the design philosophy behind Google’s approach to human-AI collaboration, as well as to evaluate the user experience of both tools. I aimed to gather actionable insights that could inform and inspire the development of my own LLM-based application.</p>
<p><img src="hero-img.jpg" class="img-fluid"></p>
<section id="learn-about" class="level2">
<h2 class="anchored" data-anchor-id="learn-about">Learn About</h2>
<p>Google Learn About is a self-guided learning tool that allows users to explore concepts across a wide range of fields. The learning experience is highly flexible and conversational, driven entirely by the flow of interaction. Users can either continue the conversation by asking their own questions or follow AI-suggested topics to further expand their knowledge.</p>
<p>Learn About functions primarily as a resource aggregation tool. It doesn’t create original articles, images, or videos (aside from some text generation), but instead curates existing online resources and generates concise summaries.</p>
<p>After answering a user’s question, it provides related webpages and articles to help expand the user’s knowledge network. However, I found this part a bit disruptive—the need to navigate to a new webpage broke the flow and slightly interrupted the overall experience. At the end of each exchange, it offers helpful defaults like “simplify,” “go deeper,” and suggested follow-up questions to guide users who might be unsure how to continue exploring the topic.</p>
<p><img src="learn-about.png" class="img-fluid"></p>
<section id="guided-freedom" class="level3">
<h3 class="anchored" data-anchor-id="guided-freedom">Guided freedom</h3>
<p>Overall, this tool doesn’t differ dramatically from the Google search engine—especially now that AI-powered summarization is integrated into search. However, what sets Learn About apart, and what I personally found to be its most valuable feature, is the thoughtful inclusion of pre-set options for users.</p>
<p>The tool strikes a strong balance between freedom and structure. It allows users to navigate topics at their own pace, customizing both the depth and speed of learning. Users can even ask the AI to generate quizzes to test their understanding of a concept. At the same time, Google clearly understands the <strong>anxiety and uncertainty</strong> that can arise when approaching a completely unfamiliar topic.</p>
<p>Learn About addresses this by offering <strong>just enough guided pathways</strong> to help users get started—without overwhelming or restricting them. When I tested the tool, I didn’t feel lost the way I often do when learning a new concept on my own, where I typically have no idea where or how to begin. Instead, I was gently guided by a few pre-set paths, which made the learning experience feel far more approachable and manageable.</p>
</section>
<section id="everthing-is-instantly-available" class="level3">
<h3 class="anchored" data-anchor-id="everthing-is-instantly-available">Everthing is instantly available</h3>
<p>Another strength of this product is its instant accessibility. Interacting with it is intuitive—users can simply highlight a term and select “What is this?” from a drop-down menu to get immediate explanations. Whether it’s a definition, an image, a concept breakdown, or even a quiz, everything is just one click away, delivered through the most intuitive user interactions.</p>
<p><strong>This ease of accessing information reflects how real learning actually happens.</strong> We rarely absorb knowledge in a perfectly sequential or structured way. Instead, we learn organically, building a web of understanding as new questions arise.</p>
<p>What’s more, I can even ask Learn About to generate a mind map of what I’ve learned so far. There are virtually no constraints on the type of output you can request. This kind of multi-modal learning experience not only makes education more engaging but also democratizes access to knowledge and significantly lowers the barriers to learning.</p>
<p><img src="learn-about-2.png" class="img-fluid"></p>
</section>
<section id="sequential-display-can-be-a-constraint" class="level3">
<h3 class="anchored" data-anchor-id="sequential-display-can-be-a-constraint">Sequential display can be a constraint</h3>
<p>However, what I don’t love about the experience is also about sequentiality. Due to the constraints of its conversational format, information can only be presented in a linear, turn-by-turn flow. If I want to explore a new concept, I have to start a new conversation turn, which often means losing track of where I was in the previous thread.</p>
<p>If I were designing this tool, I might consider using a <strong>canvas-based interface</strong> instead of a traditional chat format. A canvas would allow users to visually organize ideas, maintain context, and more easily form connections between related concepts—making the learning experience more holistic and intuitive.</p>
</section>
</section>
<section id="textfx" class="level2">
<h2 class="anchored" data-anchor-id="textfx">TextFX</h2>
<p>Google TextFX is an experimental creative writing tool powered by generative AI, designed to help writers explore language in fresh and imaginative ways. It fully leverages AI’s generative creativity to venture into unconventional directions of language construction—the kinds of patterns and possibilities that are often overlooked by humans.</p>
<p>Here’s an example of me using textFX to generate a simile about “fingerprint”:</p>
<p><img src="textFX.png" class="img-fluid"></p>
<p><img src="textFX-2.png" class="img-fluid"></p>
<section id="opening-an-unexpected-gift" class="level3">
<h3 class="anchored" data-anchor-id="opening-an-unexpected-gift">Opening an unexpected gift</h3>
<p>TextFX is quite different from Learn About. While Learn About is a practical, utility-focused tool, TextFX is clearly a creative tool—and you can sense that instantly from the user interface, with its bold, high-contrast colors and simple, playful user interactions.</p>
<p>TextFX represents a sweet spot in designing AI tools that are driven by creativity. From the moment I started using it, I noticed that the <strong>user goals are more ambiguous</strong>—people approach it with fewer expectations and more openness to discovery.</p>
<p>When comparing the emotional tone between the two tools, I’d describe the mood of using Learn About as <strong>goal-oriented</strong> and <strong>direct</strong>—you’re there to find answers. In contrast, the mood of using TextFX is rooted in <strong>curiosity</strong> and <strong>surprise</strong>. The way it presents outputs feels like <strong>unwrapping an unexpected gift</strong>, and that sense of delight is one of the tool’s most compelling design features.</p>
<p>In addition, the tool intentionally minimizes user input—asking only for a word, a concept, or a scene. Based on that, it generates a few sentences that creatively expand on the input. By encouraging users to focus on a single element, TextFX simplifies a more complex creative task, narrowing the objective and refining the output into something more polished and impactful.</p>
</section>
<section id="creative-prompting" class="level3">
<h3 class="anchored" data-anchor-id="creative-prompting">Creative prompting</h3>
<p>What’s also highly relevant to my project is the way Google’s AI team uses prompt engineering to guide the LLM in producing creative outputs. They employ a standardized prompting strategy that includes a brief explanation of the desired output (e.g., what makes a good simile), the intended format, and a few strong examples to set clear expectations.</p>
<p><img src="textFX-3.png" class="img-fluid"></p>
<p>Watching this in action is quite inspiring, as it reveals strong parallels between creative text generation and ideation—both are, at their core, games of language and concept construction. The capabilities demonstrated by TextFX serve as strong evidence that high-quality idea generation should be well within reach for LLMs.</p>
<p>However, TextFX also exposes a common weakness in creative LLM tools. After running around 20 trials, I found that only a handful—fewer than five—felt truly inspiring or exciting. Among the various creative tasks the LLM performs, it excels most at crafting similes and drawing unexpected connections between two concepts. While it handles other tasks reasonably well, the output often feels generic or lacking in creative depth, making it less useful in real-world creative settings.</p>
</section>
<section id="balance-creativity-and-utility" class="level3">
<h3 class="anchored" data-anchor-id="balance-creativity-and-utility">Balance creativity and utility</h3>
<p>The biggest takeaway from TextFX is the importance of balancing creativity and utility in an AI tool. The first step toward achieving that balance is to clearly define the primary user goal. TextFX chooses to operate as a purely creative tool, while Learn About is grounded in the practical goal of helping users learn new concepts.</p>
<p>In the context of my AI ideation partner, I’m envisioning something that sits between those two extremes. It’s practical—because at its core, it’s a problem-solving tool—but it also needs to be creative, offering fresh perspectives that make it stand out from other brainstorming aids.</p>
<p>That means the tool’s primary focus should be on delivering real value to users, just like any practical product. But at the same time, creative touches can and should be intentionally woven into the prompt engineering to spark inspiration and elevate the overall experience.</p>
</section>
</section>
<section id="notebooklm" class="level2">
<h2 class="anchored" data-anchor-id="notebooklm">NotebookLM</h2>
<p>NotebookLM shares several similarities with Learn About. Both tools have clear, distinct objectives, offer unambiguous instructions for how to navigate them, and are grounded in a practical use case. NotebookLM prompts users to upload one or more documents, which then serve as the foundation for generating notes and insights. It also reinforces a multi-modal learning framework by offering various output formats, including text summaries, audio (like podcasts), mind maps, and quizzes. Users can guide the flow of information through conversational interaction, allowing for a more tailored experience. Overall, NotebookLM builds a comprehensive and resource-rich learning environment that effectively mirrors the key stages of a typical study session—from absorbing material to reviewing and testing comprehension.</p>
<p><img src="NotebookLM.png" class="img-fluid"></p>
<section id="the-use-of-multi-modal-output" class="level3">
<h3 class="anchored" data-anchor-id="the-use-of-multi-modal-output">The use of multi-modal output</h3>
<p>One feature that really stood out to me is the flexibility of output formats that NotebookLM offers. Beyond standard text, it also supports mind map and audio generation. However, as the famous saying in product development goes, “More is not always better.” The variety of output formats only adds real value when it meaningfully contributes to helping users achieve their goals. In this case, the podcast generation feature is a brilliant addition. It directly addresses a common pain point: difficulty focusing when reading long-form text. While the interaction between the two hosts can still feel a bit unnatural at times, I was genuinely impressed by the well-structured format of the podcast—moving seamlessly from an introduction to high-level concepts, and gradually into more detailed points.</p>
<p>What surprised me most was that the podcast wasn’t just a simple repetition of the source material. Instead, it reframed the content into a natural and engaging two-person dialogue. This kind of interaction enhances the learning experience, especially since one host often plays the role of the “curious beginner,” asking the kinds of questions we might have ourselves.</p>
<p>I also tested the Interactive Mode in beta, which brought a delightful twist to the experience. The user interaction is again very straightforward–by hitting the “join” button, you join the conversation. The two hosts even greet you as if you’re joining them from another world. Similar to a text-based conversation, the direction of the podcast is driven by the user’s input, making it a fully interactive and immersive learning experience.</p>
<p><img src="NotebookLM-2.png" class="img-fluid"></p>
</section>
<section id="introducing-interactivity-to-break-the-conventions" class="level3">
<h3 class="anchored" data-anchor-id="introducing-interactivity-to-break-the-conventions">Introducing interactivity to break the conventions</h3>
<p>This feature made me reflect on how we can integrate interactivity into an AI tool in a way that feels both seamless and productive. Introducing interactivity holds two key benefits in AI product development:</p>
<ol type="1">
<li>It allows users to retain control over how things progress, helping prevent mental disengagement from the task at hand.</li>
<li>It increases the personalization of the experience, making the product more adaptable to individual needs.</li>
</ol>
<p>In this case, adding Interactive Mode to the podcast overview feature is particularly effective because it transforms what would typically be a passive, non-interactive activity into something more engaging and personal. As a result, the podcast avoids the common pitfall of feeling too generic or one-size-fits-all, and instead creates a more tailored, human-centered experience.</p>
</section>
<section id="ui-workflow" class="level3">
<h3 class="anchored" data-anchor-id="ui-workflow">UI Workflow</h3>
<p>Another point worth mentioning is the UI layout, which adopts a bento box design—juxtaposing cards, each with a different function. From left to right, users can import sources, generate summaries, and ultimately process multiple outputs to compile their notes. The layout of the cards reflects a clean and organized workflow, making the progression of tasks intuitive.</p>
<p>This kind of layout is common in AI copilot tools, and it serves as a valuable reference for my own LLM application. With multiple tasks occurring simultaneously, using separate cards to represent different steps in the workflow is an effective way to guide users through the experience, keeping it both structured and user-friendly.</p>
<p>In the next post, I’ll apply those insights that I learnt from Google’s AI products to my AI ideation application.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/jaasminew\.github\.io\/comm4190_S25_Using_LLMs_Blog\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>